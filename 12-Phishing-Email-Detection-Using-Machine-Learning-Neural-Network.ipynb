{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO5YHDkWRJWtygIHBpNAn0g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUHPLrZv_Mnr","executionInfo":{"status":"ok","timestamp":1730267927497,"user_tz":360,"elapsed":54756,"user":{"displayName":"Andrew Pownuk","userId":"03168004100943721436"}},"outputId":"bce9d156-f7a4-4147-ffb6-6202479b421c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8409 - loss: 0.4576 - val_accuracy: 0.9417 - val_loss: 0.1948\n","Epoch 2/5\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.9552 - loss: 0.1524 - val_accuracy: 0.9753 - val_loss: 0.0834\n","Epoch 3/5\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 99ms/step - accuracy: 0.9853 - loss: 0.0576 - val_accuracy: 0.9865 - val_loss: 0.0591\n","Epoch 4/5\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 73ms/step - accuracy: 0.9923 - loss: 0.0333 - val_accuracy: 0.9888 - val_loss: 0.0566\n","Epoch 5/5\n","\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step - accuracy: 0.9925 - loss: 0.0308 - val_accuracy: 0.9865 - val_loss: 0.0607\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n","\n","Accuracy: 98.74%\n","\n","Classification Report:\n","\n","              precision    recall  f1-score   support\n","\n","           0       0.99      1.00      0.99       955\n","           1       0.99      0.92      0.95       160\n","\n","    accuracy                           0.99      1115\n","   macro avg       0.99      0.96      0.97      1115\n","weighted avg       0.99      0.99      0.99      1115\n","\n","Confusion Matrix:\n","\n","[[954   1]\n"," [ 13 147]]\n","\n","Sample Predictions:\n","\n","                                                                                                                                                      Message Actual Label Predicted Label\n","               URGENT! This is the 2nd attempt to contact U!U have WON £1000CALL 09071512432 b4 300603t&csBCM4235WC1N3XX.callcost150ppmmobilesvary. max£7. 50         spam            spam\n","   Sad story of a Man - Last week was my b'day. My Wife did'nt wish me. My Parents forgot n so did my Kids . I went to work. Even my Colleagues did not wish.          ham             ham\n","                                                     Yes..he is really great..bhaji told kallis best cricketer after sachin in world:).very tough to get out.          ham             ham\n","                                                                                                                            Long time. You remember me today.          ham             ham\n","                                                                                                                                  Anything lor... U decide...          ham             ham\n","FREE>Ringtone! Reply REAL or POLY eg REAL1 1. PushButton 2. DontCha 3. BabyGoodbye 4. GoldDigger 5. WeBeBurnin 1st tone FREE and 6 more when u join for £3/wk         spam            spam\n","                                                                                I called but no one pick up e phone. I ask both of them already they said ok.          ham             ham\n","                                                                        No! But we found a diff farm shop to buy some cheese. On way back now, can i call in?          ham             ham\n","                                                                                                                           K.i will send in  &lt;#&gt;  min:)          ham             ham\n","\n","Flagged Users for Potential Phishing Attempts:\n","\n","    user_id  clicks  suspicious_downloads  unusual_time_activity  \\\n","4         5       5                     0                      1   \n","11       12       7                     1                      0   \n","15       16       5                     1                      0   \n","28       29       1                     1                      0   \n","35       36       7                     1                      0   \n","\n","    potential_phishing  \n","4                    1  \n","11                   1  \n","15                   1  \n","28                   1  \n","35                   1  \n"]}],"source":["# **Phishing Email Detection Using Neural Networks**\n","\n","# Import Libraries\n","import pandas as pd\n","import numpy as np\n","import nltk\n","import re\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from nltk.corpus import stopwords\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","\n","# Download NLTK data files\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","# Load the Dataset\n","# Download the dataset\n","!wget -q https://raw.githubusercontent.com/justmarkham/DAT8/master/data/sms.tsv\n","\n","# Read the dataset\n","df = pd.read_csv('sms.tsv', sep='\\t', header=None, names=['label', 'text'])\n","\n","# Data Preprocessing\n","# Map 'ham' to 0 and 'spam' to 1\n","df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n","\n","# Clean and preprocess the text data\n","def preprocess_text(text):\n","    # Remove non-alphabetic characters and convert to lowercase\n","    text = re.sub('[^a-zA-Z]', ' ', text).lower()\n","    # Tokenize\n","    words = nltk.word_tokenize(text)\n","    # Remove stopwords\n","    words = [word for word in words if word not in stopwords.words('english')]\n","    # Join words back into a single string\n","    return ' '.join(words)\n","\n","df['clean_text'] = df['text'].apply(preprocess_text)\n","\n","# Prepare the data for the neural network\n","tokenizer = Tokenizer(num_words=5000)\n","tokenizer.fit_on_texts(df['clean_text'])\n","\n","X = tokenizer.texts_to_sequences(df['clean_text'])\n","X = pad_sequences(X, maxlen=100)\n","\n","y = df['label'].values\n","\n","# Split the Dataset\n","X_train, X_test, y_train, y_test, text_train, text_test = train_test_split(\n","    X, y, df['text'], test_size=0.20, random_state=0)\n","\n","# Build the Neural Network Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=5000, output_dim=64, input_length=100))\n","model.add(LSTM(64, dropout=0.5, recurrent_dropout=0.5))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the Model\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train the Model\n","history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n","\n","# Evaluate the Model\n","# Predict on the test set\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"\\nAccuracy: {accuracy * 100:.2f}%\\n\")\n","\n","# Display classification report\n","print(\"Classification Report:\\n\")\n","print(classification_report(y_test, y_pred))\n","\n","# Display confusion matrix\n","print(\"Confusion Matrix:\\n\")\n","print(confusion_matrix(y_test, y_pred))\n","\n","# Display Sample Predictions\n","print(\"\\nSample Predictions:\\n\")\n","\n","# Create a DataFrame with the actual and predicted labels\n","results_df = pd.DataFrame({\n","    'Message': text_test,\n","    'Actual Label': y_test,\n","    'Predicted Label': y_pred\n","})\n","\n","# Map labels back to 'ham' and 'spam'\n","label_mapping = {0: 'ham', 1: 'spam'}\n","results_df['Actual Label'] = results_df['Actual Label'].map(label_mapping)\n","results_df['Predicted Label'] = results_df['Predicted Label'].map(label_mapping)\n","\n","# Display a few sample messages with their actual and predicted labels\n","sample_results = results_df.sample(9, random_state=1)\n","print(sample_results[['Message', 'Actual Label', 'Predicted Label']].to_string(index=False))\n","\n","# Behavioral Analysis Simulation\n","# Simulated user behavior data\n","np.random.seed(0)  # For reproducibility\n","user_data = pd.DataFrame({\n","    'user_id': np.arange(1, 101),\n","    'clicks': np.random.poisson(5, 100),\n","    'suspicious_downloads': np.random.binomial(1, 0.05, 100),\n","    'unusual_time_activity': np.random.binomial(1, 0.1, 100)\n","})\n","\n","# Identify users with potential phishing interaction\n","user_data['potential_phishing'] = user_data.apply(\n","    lambda x: 1 if x['clicks'] > 10 or x['suspicious_downloads'] == 1 or x['unusual_time_activity'] == 1 else 0,\n","    axis=1\n",")\n","\n","# Display users flagged for potential phishing\n","flagged_users = user_data[user_data['potential_phishing'] == 1]\n","print(\"\\nFlagged Users for Potential Phishing Attempts:\\n\")\n","print(flagged_users.head())\n"]}]}